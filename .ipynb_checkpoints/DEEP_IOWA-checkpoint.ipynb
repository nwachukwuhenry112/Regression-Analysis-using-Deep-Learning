{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Henry\\\\DEEPLEARNING_IOWA'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\henry\\anaconda3\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\henry\\anaconda3\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from keras) (1.5.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\henry\\anaconda3\\lib\\site-packages (from keras) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from keras) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import seed \n",
    "seed(1) \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "!pip install keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_8 = pd.read_csv('sensitivity_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>SalePrice_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.207142</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>1.050994</td>\n",
       "      <td>0.878668</td>\n",
       "      <td>0.575425</td>\n",
       "      <td>0.370333</td>\n",
       "      <td>-0.951226</td>\n",
       "      <td>0.311725</td>\n",
       "      <td>12.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.091886</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>0.156734</td>\n",
       "      <td>-0.429577</td>\n",
       "      <td>1.171992</td>\n",
       "      <td>-0.482512</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>0.311725</td>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotArea  OverallQual  YearBuilt  YearRemodAdd  BsmtFinSF1  GrLivArea  \\\n",
       "0 -0.207142     0.651479   1.050994      0.878668    0.575425   0.370333   \n",
       "1 -0.091886    -0.071836   0.156734     -0.429577    1.171992  -0.482512   \n",
       "\n",
       "   Fireplaces  GarageCars  SalePrice_log  \n",
       "0   -0.951226    0.311725      12.247694  \n",
       "1    0.600495    0.311725      12.109011  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity_8.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_4 = pd.read_csv('sensitivity_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>SalePrice_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.207142</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>1.050994</td>\n",
       "      <td>0.370333</td>\n",
       "      <td>12.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.091886</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>0.156734</td>\n",
       "      <td>-0.482512</td>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotArea  OverallQual  YearBuilt  GrLivArea  SalePrice_log\n",
       "0 -0.207142     0.651479   1.050994   0.370333      12.247694\n",
       "1 -0.091886    -0.071836   0.156734  -0.482512      12.109011"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity_4.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_4.columns = ['']*len(sensitivity_4.columns)\n",
    "sensitivity_4.index = ['']*len(sensitivity_4.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>-0.207142</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>1.050994</td>\n",
       "      <td>0.370333</td>\n",
       "      <td>12.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>-0.091886</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>0.156734</td>\n",
       "      <td>-0.482512</td>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   \n",
       " -0.207142  0.651479  1.050994  0.370333  12.247694\n",
       " -0.091886 -0.071836  0.156734 -0.482512  12.109011"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity_4.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_8.columns = ['']*len(sensitivity_8.columns)\n",
    "sensitivity_8.index = ['']*len(sensitivity_8.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>-0.207142</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>1.050994</td>\n",
       "      <td>0.878668</td>\n",
       "      <td>0.575425</td>\n",
       "      <td>0.370333</td>\n",
       "      <td>-0.951226</td>\n",
       "      <td>0.311725</td>\n",
       "      <td>12.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>-0.091886</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>0.156734</td>\n",
       "      <td>-0.429577</td>\n",
       "      <td>1.171992</td>\n",
       "      <td>-0.482512</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>0.311725</td>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        \\\n",
       " -0.207142  0.651479  1.050994  0.878668  0.575425  0.370333 -0.951226   \n",
       " -0.091886 -0.071836  0.156734 -0.429577  1.171992 -0.482512  0.600495   \n",
       "\n",
       "                       \n",
       "  0.311725  12.247694  \n",
       "  0.311725  12.109011  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity_8.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " train, validate, test = \\\n",
    "              np.split(sensitivity_8.sample(frac=1, random_state=42), \n",
    "                       [int(.6*len(sensitivity_8)), int(.8*len(sensitivity_8))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((876, 9), (292, 9), (292, 9))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input =train.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target= train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_input = validate.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_target= validate.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target= test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELING FOR 8 FEATURES\n",
    "# build the model using Keras approach\n",
    "input_size = 8   # number of features\n",
    "from sklearn.metrics import r2_score\n",
    "output_size = 1    \n",
    "hidden_layer_size =50  \n",
    "Early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "     tf.keras.layers.Dense(hidden_layer_size,activation = 'relu'),\n",
    "     tf.keras.layers.Dense(hidden_layer_size,activation = 'relu'),\n",
    "     tf.keras.layers.Dense(hidden_layer_size,activation = 'relu'),\n",
    "       tf.keras.layers.Dense(hidden_layer_size,activation = 'tanh'),\n",
    "     tf.keras.layers.Dense(hidden_layer_size,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(output_size,activation ='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss ='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 1s - loss: 137.6701 - mse: 137.6701 - val_loss: 123.0223 - val_mse: 123.0223\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 107.2069 - mse: 107.2069 - val_loss: 82.1756 - val_mse: 82.1757\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 60.4037 - mse: 60.4037 - val_loss: 31.8368 - val_mse: 31.8368\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 16.7095 - mse: 16.7095 - val_loss: 3.1507 - val_mse: 3.1507\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 1.3589 - mse: 1.3589 - val_loss: 1.9110 - val_mse: 1.9110\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 1.9577 - mse: 1.9577 - val_loss: 1.2824 - val_mse: 1.2824\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 0.5798 - mse: 0.5798 - val_loss: 0.3002 - val_mse: 0.3002\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 0.3716 - mse: 0.3716 - val_loss: 0.4128 - val_mse: 0.4128\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 0.2791 - mse: 0.2791 - val_loss: 0.2242 - val_mse: 0.2242\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 0.1953 - mse: 0.1953 - val_loss: 0.2336 - val_mse: 0.2336\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 0.1795 - mse: 0.1795 - val_loss: 0.1885 - val_mse: 0.1885\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 0.1545 - mse: 0.1545 - val_loss: 0.1779 - val_mse: 0.1779\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 0.1438 - mse: 0.1438 - val_loss: 0.1624 - val_mse: 0.1624\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 0.1312 - mse: 0.1312 - val_loss: 0.1530 - val_mse: 0.1530\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 0.1230 - mse: 0.1230 - val_loss: 0.1427 - val_mse: 0.1427\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 0.1147 - mse: 0.1147 - val_loss: 0.1341 - val_mse: 0.1341\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 0.1073 - mse: 0.1073 - val_loss: 0.1262 - val_mse: 0.1262\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 0.1009 - mse: 0.1009 - val_loss: 0.1188 - val_mse: 0.1188\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 0.0946 - mse: 0.0946 - val_loss: 0.1120 - val_mse: 0.1120\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 0.0889 - mse: 0.0889 - val_loss: 0.1056 - val_mse: 0.1056\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 0.0835 - mse: 0.0835 - val_loss: 0.0994 - val_mse: 0.0994\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 0.0781 - mse: 0.0781 - val_loss: 0.0935 - val_mse: 0.0935\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 0.0730 - mse: 0.0730 - val_loss: 0.0876 - val_mse: 0.0876\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 0.0678 - mse: 0.0678 - val_loss: 0.0819 - val_mse: 0.0819\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 0.0630 - mse: 0.0630 - val_loss: 0.0762 - val_mse: 0.0762\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 0.0582 - mse: 0.0582 - val_loss: 0.0708 - val_mse: 0.0708\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0657 - val_mse: 0.0657\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 0.0494 - mse: 0.0494 - val_loss: 0.0610 - val_mse: 0.0610\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0569 - val_mse: 0.0569\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0533 - val_mse: 0.0533\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 0.0402 - mse: 0.0402 - val_loss: 0.0502 - val_mse: 0.0502\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0450 - val_mse: 0.0450\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0425 - val_mse: 0.0425\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 65/100\n",
      "9/9 - 0s - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 67/100\n",
      "9/9 - 0s - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 68/100\n",
      "9/9 - 0s - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 69/100\n",
      "9/9 - 0s - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 70/100\n",
      "9/9 - 0s - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 71/100\n",
      "9/9 - 0s - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 72/100\n",
      "9/9 - 0s - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 73/100\n",
      "9/9 - 0s - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 74/100\n",
      "9/9 - 0s - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 75/100\n",
      "9/9 - 0s - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 76/100\n",
      "9/9 - 0s - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 77/100\n",
      "9/9 - 0s - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 78/100\n",
      "9/9 - 0s - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 79/100\n",
      "9/9 - 0s - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 80/100\n",
      "9/9 - 0s - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 81/100\n",
      "9/9 - 0s - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 82/100\n",
      "9/9 - 0s - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 83/100\n",
      "9/9 - 0s - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 84/100\n",
      "9/9 - 0s - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 85/100\n",
      "9/9 - 0s - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 86/100\n",
      "9/9 - 0s - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 87/100\n",
      "9/9 - 0s - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 88/100\n",
      "9/9 - 0s - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 89/100\n",
      "9/9 - 0s - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 90/100\n",
      "9/9 - 0s - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 91/100\n",
      "9/9 - 0s - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 92/100\n",
      "9/9 - 0s - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 93/100\n",
      "9/9 - 0s - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0137 - val_mse: 0.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "9/9 - 0s - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 95/100\n",
      "9/9 - 0s - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 96/100\n",
      "9/9 - 0s - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 97/100\n",
      "9/9 - 0s - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0142 - val_mse: 0.0142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14afe575040>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "max_epochs= 100\n",
    "model.fit(train_input,train_target,batch_size=batch_size ,epochs=max_epochs,callbacks=[Early_stopping],validation_data=(validation_input ,validation_target),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.925217 ],\n",
       "       [11.857141 ],\n",
       "       [12.042654 ],\n",
       "       [12.081725 ],\n",
       "       [11.931429 ],\n",
       "       [12.118069 ],\n",
       "       [12.558153 ],\n",
       "       [12.303955 ],\n",
       "       [11.668831 ],\n",
       "       [11.695326 ],\n",
       "       [11.756712 ],\n",
       "       [11.659082 ],\n",
       "       [12.2025585],\n",
       "       [12.102034 ],\n",
       "       [11.99542  ],\n",
       "       [11.619103 ],\n",
       "       [11.707787 ],\n",
       "       [12.052517 ],\n",
       "       [12.138067 ],\n",
       "       [11.934806 ],\n",
       "       [12.0338955],\n",
       "       [11.912954 ],\n",
       "       [12.36347  ],\n",
       "       [11.69282  ],\n",
       "       [12.303667 ],\n",
       "       [12.273973 ],\n",
       "       [12.111347 ],\n",
       "       [12.110353 ],\n",
       "       [11.913942 ],\n",
       "       [11.854351 ],\n",
       "       [11.744205 ],\n",
       "       [11.611697 ],\n",
       "       [12.326042 ],\n",
       "       [12.5190935],\n",
       "       [11.906069 ],\n",
       "       [12.166219 ],\n",
       "       [12.333403 ],\n",
       "       [11.768665 ],\n",
       "       [11.681255 ],\n",
       "       [12.039    ],\n",
       "       [12.170199 ],\n",
       "       [11.708139 ],\n",
       "       [11.549299 ],\n",
       "       [11.6180525],\n",
       "       [12.573683 ],\n",
       "       [12.458464 ],\n",
       "       [12.439518 ],\n",
       "       [11.703639 ],\n",
       "       [11.657178 ],\n",
       "       [12.244221 ],\n",
       "       [11.616191 ],\n",
       "       [11.998199 ],\n",
       "       [11.816157 ],\n",
       "       [11.76434  ],\n",
       "       [12.20788  ],\n",
       "       [12.155411 ],\n",
       "       [11.72365  ],\n",
       "       [11.6107   ],\n",
       "       [11.734648 ],\n",
       "       [12.0047   ],\n",
       "       [11.823299 ],\n",
       "       [12.061802 ],\n",
       "       [11.797214 ],\n",
       "       [12.405453 ],\n",
       "       [11.905141 ],\n",
       "       [11.819251 ],\n",
       "       [11.974382 ],\n",
       "       [12.425089 ],\n",
       "       [11.801267 ],\n",
       "       [12.309015 ],\n",
       "       [11.79592  ],\n",
       "       [12.368921 ],\n",
       "       [12.0822735],\n",
       "       [11.538994 ],\n",
       "       [11.893345 ],\n",
       "       [11.673094 ],\n",
       "       [11.627184 ],\n",
       "       [11.754339 ],\n",
       "       [11.653446 ],\n",
       "       [11.88545  ],\n",
       "       [11.918126 ],\n",
       "       [12.071465 ],\n",
       "       [12.006471 ],\n",
       "       [12.326672 ],\n",
       "       [12.415058 ],\n",
       "       [12.208506 ],\n",
       "       [12.06373  ],\n",
       "       [12.467804 ],\n",
       "       [12.388956 ],\n",
       "       [11.648444 ],\n",
       "       [12.286541 ],\n",
       "       [12.399665 ],\n",
       "       [12.193265 ],\n",
       "       [12.295864 ],\n",
       "       [11.753782 ],\n",
       "       [12.139935 ],\n",
       "       [11.7411995],\n",
       "       [11.794386 ],\n",
       "       [11.75971  ],\n",
       "       [12.416834 ],\n",
       "       [12.410482 ],\n",
       "       [11.788247 ],\n",
       "       [12.437315 ],\n",
       "       [12.396807 ],\n",
       "       [11.971223 ],\n",
       "       [12.043095 ],\n",
       "       [12.367168 ],\n",
       "       [11.976551 ],\n",
       "       [12.414112 ],\n",
       "       [11.843546 ],\n",
       "       [12.004516 ],\n",
       "       [11.715746 ],\n",
       "       [11.765221 ],\n",
       "       [12.392553 ],\n",
       "       [11.617277 ],\n",
       "       [11.737537 ],\n",
       "       [12.496164 ],\n",
       "       [11.81454  ],\n",
       "       [12.1278305],\n",
       "       [11.549028 ],\n",
       "       [11.802952 ],\n",
       "       [12.399773 ],\n",
       "       [11.983051 ],\n",
       "       [11.665616 ],\n",
       "       [11.891647 ],\n",
       "       [11.735222 ],\n",
       "       [12.018312 ],\n",
       "       [12.151724 ],\n",
       "       [12.007621 ],\n",
       "       [12.203627 ],\n",
       "       [12.169241 ],\n",
       "       [12.351676 ],\n",
       "       [11.921474 ],\n",
       "       [11.774914 ],\n",
       "       [11.91838  ],\n",
       "       [11.809612 ],\n",
       "       [11.70347  ],\n",
       "       [11.9307785],\n",
       "       [12.449847 ],\n",
       "       [11.9421425],\n",
       "       [11.804184 ],\n",
       "       [12.412035 ],\n",
       "       [12.018777 ],\n",
       "       [12.528126 ],\n",
       "       [11.751313 ],\n",
       "       [12.361739 ],\n",
       "       [11.973204 ],\n",
       "       [11.789472 ],\n",
       "       [12.019941 ],\n",
       "       [11.982239 ],\n",
       "       [11.950461 ],\n",
       "       [12.001362 ],\n",
       "       [12.052004 ],\n",
       "       [11.792411 ],\n",
       "       [11.984375 ],\n",
       "       [11.713099 ],\n",
       "       [11.810609 ],\n",
       "       [11.655967 ],\n",
       "       [12.293371 ],\n",
       "       [11.657885 ],\n",
       "       [11.876139 ],\n",
       "       [12.26762  ],\n",
       "       [12.084255 ],\n",
       "       [12.229092 ],\n",
       "       [11.757732 ],\n",
       "       [12.453437 ],\n",
       "       [12.480065 ],\n",
       "       [11.7135315],\n",
       "       [11.681334 ],\n",
       "       [12.485308 ],\n",
       "       [11.625402 ],\n",
       "       [11.724886 ],\n",
       "       [11.771601 ],\n",
       "       [11.800707 ],\n",
       "       [11.881758 ],\n",
       "       [12.169742 ],\n",
       "       [12.370426 ],\n",
       "       [11.938591 ],\n",
       "       [11.825398 ],\n",
       "       [11.92952  ],\n",
       "       [12.1028805],\n",
       "       [11.879821 ],\n",
       "       [12.241331 ],\n",
       "       [11.724977 ],\n",
       "       [12.519537 ],\n",
       "       [11.692586 ],\n",
       "       [11.661385 ],\n",
       "       [12.302762 ],\n",
       "       [11.88274  ],\n",
       "       [11.775734 ],\n",
       "       [11.670329 ],\n",
       "       [11.866497 ],\n",
       "       [12.091755 ],\n",
       "       [11.584161 ],\n",
       "       [12.325285 ],\n",
       "       [11.889154 ],\n",
       "       [12.416045 ],\n",
       "       [11.820242 ],\n",
       "       [12.07812  ],\n",
       "       [12.114986 ],\n",
       "       [11.692698 ],\n",
       "       [12.468779 ],\n",
       "       [12.20982  ],\n",
       "       [11.969748 ],\n",
       "       [11.871389 ],\n",
       "       [11.955233 ],\n",
       "       [12.233074 ],\n",
       "       [11.715527 ],\n",
       "       [11.912876 ],\n",
       "       [12.283982 ],\n",
       "       [11.836462 ],\n",
       "       [12.08295  ],\n",
       "       [12.271313 ],\n",
       "       [12.125202 ],\n",
       "       [11.852972 ],\n",
       "       [11.63521  ],\n",
       "       [12.032104 ],\n",
       "       [12.538303 ],\n",
       "       [11.6406   ],\n",
       "       [12.082243 ],\n",
       "       [12.430531 ],\n",
       "       [11.872884 ],\n",
       "       [11.711824 ],\n",
       "       [12.117242 ],\n",
       "       [11.69185  ],\n",
       "       [11.70551  ],\n",
       "       [11.971277 ],\n",
       "       [12.4625435],\n",
       "       [12.036007 ],\n",
       "       [11.91056  ],\n",
       "       [11.92111  ],\n",
       "       [12.261679 ],\n",
       "       [11.772692 ],\n",
       "       [12.032555 ],\n",
       "       [12.003779 ],\n",
       "       [12.418982 ],\n",
       "       [12.390622 ],\n",
       "       [12.222241 ],\n",
       "       [11.640993 ],\n",
       "       [12.207675 ],\n",
       "       [12.182969 ],\n",
       "       [12.462521 ],\n",
       "       [11.82281  ],\n",
       "       [11.975601 ],\n",
       "       [12.00337  ],\n",
       "       [11.747523 ],\n",
       "       [12.434619 ],\n",
       "       [11.675421 ],\n",
       "       [12.300477 ],\n",
       "       [12.030344 ],\n",
       "       [12.482365 ],\n",
       "       [11.636185 ],\n",
       "       [11.914097 ],\n",
       "       [12.188241 ],\n",
       "       [11.732339 ],\n",
       "       [12.3604555],\n",
       "       [12.114845 ],\n",
       "       [12.074537 ],\n",
       "       [11.976315 ],\n",
       "       [12.126191 ],\n",
       "       [12.380557 ],\n",
       "       [11.796436 ],\n",
       "       [12.107956 ],\n",
       "       [12.059429 ],\n",
       "       [11.781839 ],\n",
       "       [11.529497 ],\n",
       "       [11.691707 ],\n",
       "       [12.180849 ],\n",
       "       [12.116867 ],\n",
       "       [11.949293 ],\n",
       "       [11.671083 ],\n",
       "       [12.084057 ],\n",
       "       [12.13011  ],\n",
       "       [12.471898 ],\n",
       "       [12.37418  ],\n",
       "       [12.501392 ],\n",
       "       [11.653299 ],\n",
       "       [12.278955 ],\n",
       "       [12.117367 ],\n",
       "       [11.600477 ],\n",
       "       [12.148671 ],\n",
       "       [12.004509 ],\n",
       "       [11.737951 ],\n",
       "       [11.994701 ],\n",
       "       [12.070406 ],\n",
       "       [11.592713 ],\n",
       "       [12.448352 ],\n",
       "       [12.01399  ],\n",
       "       [11.904484 ],\n",
       "       [11.7096195],\n",
       "       [11.844244 ],\n",
       "       [12.169435 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 556us/step - loss: 0.0134 - mse: 0.0134\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy = model.evaluate(test_input,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8553568009036763\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(test_target,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case for sensitivity_4 \n",
    "train, validate, test = \\\n",
    "              np.split(sensitivity_4.sample(frac=1, random_state=42), \n",
    "                       [int(.6*len(sensitivity_4)), int(.8*len(sensitivity_4))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((876, 5), (292, 5), (292, 5))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_2 =train.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_2= train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_input_2 =validate.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_target_2= validate.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_2 =test.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target_2= test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4   # number of features\n",
    "\n",
    "output_size = 1    \n",
    "hidden_layer_size =100  \n",
    "Early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "     tf.keras.layers.Dense(hidden_layer_size,activation = 'relu'),\n",
    "     tf.keras.layers.Dense(hidden_layer_size,activation = 'relu'),\n",
    "       tf.keras.layers.Dense(hidden_layer_size,activation = 'tanh'),\n",
    "     tf.keras.layers.Dense(hidden_layer_size,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(output_size,activation ='linear')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer='adam',loss ='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 1s - loss: 131.4688 - mse: 131.4688 - val_loss: 110.0995 - val_mse: 110.0995\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 86.3835 - mse: 86.3835 - val_loss: 44.7323 - val_mse: 44.7323\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 21.9342 - mse: 21.9342 - val_loss: 12.7564 - val_mse: 12.7564\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 13.1599 - mse: 13.1599 - val_loss: 9.4188 - val_mse: 9.4188\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 5.6361 - mse: 5.6361 - val_loss: 5.7512 - val_mse: 5.7512\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 4.8387 - mse: 4.8387 - val_loss: 3.9657 - val_mse: 3.9657\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 3.0007 - mse: 3.0007 - val_loss: 3.1684 - val_mse: 3.1684\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 2.2706 - mse: 2.2706 - val_loss: 2.2110 - val_mse: 2.2110\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 1.7022 - mse: 1.7022 - val_loss: 1.6512 - val_mse: 1.6512\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 1.2335 - mse: 1.2335 - val_loss: 1.2211 - val_mse: 1.2211\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 0.9136 - mse: 0.9136 - val_loss: 0.8837 - val_mse: 0.8837\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 0.6407 - mse: 0.6407 - val_loss: 0.6138 - val_mse: 0.6138\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 0.4533 - mse: 0.4533 - val_loss: 0.4359 - val_mse: 0.4359\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 0.3222 - mse: 0.3222 - val_loss: 0.3074 - val_mse: 0.3074\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 0.2280 - mse: 0.2280 - val_loss: 0.2223 - val_mse: 0.2223\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 0.1679 - mse: 0.1679 - val_loss: 0.1664 - val_mse: 0.1664\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 0.1282 - mse: 0.1282 - val_loss: 0.1285 - val_mse: 0.1285\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 0.1003 - mse: 0.1003 - val_loss: 0.1017 - val_mse: 0.1017\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 0.0809 - mse: 0.0809 - val_loss: 0.0826 - val_mse: 0.0826\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 0.0680 - mse: 0.0680 - val_loss: 0.0696 - val_mse: 0.0696\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 0.0591 - mse: 0.0591 - val_loss: 0.0607 - val_mse: 0.0607\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0543 - val_mse: 0.0543\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0496 - val_mse: 0.0496\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0460 - val_mse: 0.0460\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 0.0413 - mse: 0.0413 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 0.0389 - mse: 0.0389 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0369 - val_mse: 0.0369\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0321 - val_mse: 0.0321\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 65/100\n",
      "9/9 - 0s - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 67/100\n",
      "9/9 - 0s - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 68/100\n",
      "9/9 - 0s - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 69/100\n",
      "9/9 - 0s - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 70/100\n",
      "9/9 - 0s - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 71/100\n",
      "9/9 - 0s - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 72/100\n",
      "9/9 - 0s - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 73/100\n",
      "9/9 - 0s - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 74/100\n",
      "9/9 - 0s - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 75/100\n",
      "9/9 - 0s - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 76/100\n",
      "9/9 - 0s - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 77/100\n",
      "9/9 - 0s - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 78/100\n",
      "9/9 - 0s - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 79/100\n",
      "9/9 - 0s - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 80/100\n",
      "9/9 - 0s - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 81/100\n",
      "9/9 - 0s - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 82/100\n",
      "9/9 - 0s - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 83/100\n",
      "9/9 - 0s - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 84/100\n",
      "9/9 - 0s - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 85/100\n",
      "9/9 - 0s - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 86/100\n",
      "9/9 - 0s - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 87/100\n",
      "9/9 - 0s - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 88/100\n",
      "9/9 - 0s - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 89/100\n",
      "9/9 - 0s - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 90/100\n",
      "9/9 - 0s - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 91/100\n",
      "9/9 - 0s - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 92/100\n",
      "9/9 - 0s - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 93/100\n",
      "9/9 - 0s - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0171 - val_mse: 0.0171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "9/9 - 0s - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 95/100\n",
      "9/9 - 0s - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 96/100\n",
      "9/9 - 0s - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 97/100\n",
      "9/9 - 0s - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 98/100\n",
      "9/9 - 0s - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 99/100\n",
      "9/9 - 0s - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 100/100\n",
      "9/9 - 0s - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0166 - val_mse: 0.0166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14a860283d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "max_epochs= 100\n",
    "model_2.fit(train_input_2,train_target_2,shuffle=False,batch_size=batch_size ,epochs=max_epochs,callbacks=[Early_stopping],validation_data=(validate_input_2 ,validate_target_2),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_1 = model_2.predict(test_input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.847141 ],\n",
       "       [12.114955 ],\n",
       "       [11.975234 ],\n",
       "       [12.124514 ],\n",
       "       [11.977237 ],\n",
       "       [12.084606 ],\n",
       "       [12.582091 ],\n",
       "       [12.296339 ],\n",
       "       [11.616135 ],\n",
       "       [11.739735 ],\n",
       "       [11.633636 ],\n",
       "       [11.619243 ],\n",
       "       [12.186967 ],\n",
       "       [12.140312 ],\n",
       "       [11.806213 ],\n",
       "       [11.701978 ],\n",
       "       [11.722309 ],\n",
       "       [12.118452 ],\n",
       "       [12.14487  ],\n",
       "       [11.918287 ],\n",
       "       [12.009258 ],\n",
       "       [11.938159 ],\n",
       "       [12.2493725],\n",
       "       [11.749655 ],\n",
       "       [12.362102 ],\n",
       "       [12.2239   ],\n",
       "       [12.062626 ],\n",
       "       [12.149012 ],\n",
       "       [11.99249  ],\n",
       "       [11.87826  ],\n",
       "       [11.657387 ],\n",
       "       [11.594501 ],\n",
       "       [12.326922 ],\n",
       "       [12.5276   ],\n",
       "       [11.923531 ],\n",
       "       [12.195913 ],\n",
       "       [12.320524 ],\n",
       "       [11.757035 ],\n",
       "       [11.646706 ],\n",
       "       [12.091304 ],\n",
       "       [12.115984 ],\n",
       "       [11.624777 ],\n",
       "       [11.5341015],\n",
       "       [11.73362  ],\n",
       "       [12.426247 ],\n",
       "       [12.407505 ],\n",
       "       [12.497588 ],\n",
       "       [11.784541 ],\n",
       "       [11.712916 ],\n",
       "       [12.204909 ],\n",
       "       [11.638353 ],\n",
       "       [12.00508  ],\n",
       "       [11.842341 ],\n",
       "       [11.794551 ],\n",
       "       [12.1699505],\n",
       "       [12.136508 ],\n",
       "       [11.845447 ],\n",
       "       [11.593931 ],\n",
       "       [11.758293 ],\n",
       "       [11.841636 ],\n",
       "       [11.882668 ],\n",
       "       [12.021312 ],\n",
       "       [11.876848 ],\n",
       "       [12.397045 ],\n",
       "       [11.919877 ],\n",
       "       [11.792801 ],\n",
       "       [11.905288 ],\n",
       "       [12.368875 ],\n",
       "       [11.968541 ],\n",
       "       [12.306855 ],\n",
       "       [11.83829  ],\n",
       "       [12.425878 ],\n",
       "       [11.8857765],\n",
       "       [11.53498  ],\n",
       "       [11.845363 ],\n",
       "       [11.550177 ],\n",
       "       [11.585655 ],\n",
       "       [11.891238 ],\n",
       "       [11.598495 ],\n",
       "       [11.890741 ],\n",
       "       [11.980024 ],\n",
       "       [12.11688  ],\n",
       "       [12.079715 ],\n",
       "       [12.22616  ],\n",
       "       [12.345541 ],\n",
       "       [12.191153 ],\n",
       "       [12.128256 ],\n",
       "       [12.483489 ],\n",
       "       [12.353955 ],\n",
       "       [11.746587 ],\n",
       "       [12.328737 ],\n",
       "       [12.401175 ],\n",
       "       [12.207034 ],\n",
       "       [12.340255 ],\n",
       "       [11.837695 ],\n",
       "       [12.119048 ],\n",
       "       [11.732778 ],\n",
       "       [11.655712 ],\n",
       "       [11.872902 ],\n",
       "       [12.36645  ],\n",
       "       [12.334328 ],\n",
       "       [11.598619 ],\n",
       "       [12.264604 ],\n",
       "       [12.315557 ],\n",
       "       [11.997249 ],\n",
       "       [12.035237 ],\n",
       "       [12.273435 ],\n",
       "       [11.922358 ],\n",
       "       [12.311707 ],\n",
       "       [11.713793 ],\n",
       "       [11.876146 ],\n",
       "       [11.724608 ],\n",
       "       [12.043776 ],\n",
       "       [12.450542 ],\n",
       "       [11.749847 ],\n",
       "       [11.842599 ],\n",
       "       [12.49141  ],\n",
       "       [11.725569 ],\n",
       "       [12.151832 ],\n",
       "       [11.503387 ],\n",
       "       [11.78456  ],\n",
       "       [12.431414 ],\n",
       "       [12.0156975],\n",
       "       [11.701118 ],\n",
       "       [11.798269 ],\n",
       "       [11.863044 ],\n",
       "       [11.859895 ],\n",
       "       [12.079746 ],\n",
       "       [11.942845 ],\n",
       "       [12.221871 ],\n",
       "       [12.211382 ],\n",
       "       [12.257052 ],\n",
       "       [11.946778 ],\n",
       "       [11.892436 ],\n",
       "       [11.832647 ],\n",
       "       [11.839165 ],\n",
       "       [11.719137 ],\n",
       "       [11.888884 ],\n",
       "       [12.4289055],\n",
       "       [11.960493 ],\n",
       "       [11.659469 ],\n",
       "       [12.374425 ],\n",
       "       [12.050786 ],\n",
       "       [12.528918 ],\n",
       "       [11.854776 ],\n",
       "       [12.23908  ],\n",
       "       [11.934821 ],\n",
       "       [11.721676 ],\n",
       "       [12.067999 ],\n",
       "       [11.742095 ],\n",
       "       [12.053826 ],\n",
       "       [12.003785 ],\n",
       "       [12.143425 ],\n",
       "       [11.771452 ],\n",
       "       [12.003194 ],\n",
       "       [11.661671 ],\n",
       "       [11.954204 ],\n",
       "       [11.680955 ],\n",
       "       [12.28649  ],\n",
       "       [11.67163  ],\n",
       "       [11.933172 ],\n",
       "       [12.17913  ],\n",
       "       [11.993522 ],\n",
       "       [12.246531 ],\n",
       "       [11.801474 ],\n",
       "       [12.499292 ],\n",
       "       [12.444967 ],\n",
       "       [11.650821 ],\n",
       "       [11.624274 ],\n",
       "       [12.455125 ],\n",
       "       [11.585127 ],\n",
       "       [11.76895  ],\n",
       "       [11.9485235],\n",
       "       [11.824452 ],\n",
       "       [11.878627 ],\n",
       "       [12.130946 ],\n",
       "       [12.376851 ],\n",
       "       [11.926566 ],\n",
       "       [11.751717 ],\n",
       "       [11.941971 ],\n",
       "       [12.152546 ],\n",
       "       [11.837036 ],\n",
       "       [12.196811 ],\n",
       "       [11.843098 ],\n",
       "       [12.488371 ],\n",
       "       [11.742627 ],\n",
       "       [11.699445 ],\n",
       "       [12.185515 ],\n",
       "       [11.722188 ],\n",
       "       [11.729696 ],\n",
       "       [11.618099 ],\n",
       "       [11.842486 ],\n",
       "       [12.126999 ],\n",
       "       [11.61317  ],\n",
       "       [12.319267 ],\n",
       "       [11.882845 ],\n",
       "       [12.386856 ],\n",
       "       [11.835284 ],\n",
       "       [12.1005125],\n",
       "       [12.139738 ],\n",
       "       [11.771494 ],\n",
       "       [12.473555 ],\n",
       "       [12.16809  ],\n",
       "       [11.943987 ],\n",
       "       [11.834247 ],\n",
       "       [11.834363 ],\n",
       "       [12.20245  ],\n",
       "       [11.770159 ],\n",
       "       [11.917158 ],\n",
       "       [12.201528 ],\n",
       "       [11.947992 ],\n",
       "       [12.027492 ],\n",
       "       [12.223126 ],\n",
       "       [12.246593 ],\n",
       "       [11.900482 ],\n",
       "       [11.605346 ],\n",
       "       [11.939551 ],\n",
       "       [12.5436125],\n",
       "       [11.584452 ],\n",
       "       [12.136849 ],\n",
       "       [12.457264 ],\n",
       "       [11.756004 ],\n",
       "       [11.782374 ],\n",
       "       [12.086353 ],\n",
       "       [11.725704 ],\n",
       "       [11.738942 ],\n",
       "       [12.168284 ],\n",
       "       [12.361372 ],\n",
       "       [11.968738 ],\n",
       "       [11.917575 ],\n",
       "       [11.8270855],\n",
       "       [12.191048 ],\n",
       "       [11.812874 ],\n",
       "       [12.060085 ],\n",
       "       [12.026869 ],\n",
       "       [12.391985 ],\n",
       "       [12.379066 ],\n",
       "       [12.233855 ],\n",
       "       [11.556773 ],\n",
       "       [12.194656 ],\n",
       "       [12.159426 ],\n",
       "       [12.440575 ],\n",
       "       [11.89134  ],\n",
       "       [11.905288 ],\n",
       "       [11.943305 ],\n",
       "       [11.865038 ],\n",
       "       [12.476221 ],\n",
       "       [11.684324 ],\n",
       "       [12.286954 ],\n",
       "       [12.018026 ],\n",
       "       [12.537288 ],\n",
       "       [11.7520275],\n",
       "       [11.827082 ],\n",
       "       [12.263821 ],\n",
       "       [11.737232 ],\n",
       "       [12.279385 ],\n",
       "       [12.074167 ],\n",
       "       [12.10274  ],\n",
       "       [11.90995  ],\n",
       "       [12.17549  ],\n",
       "       [12.308119 ],\n",
       "       [11.940624 ],\n",
       "       [12.02282  ],\n",
       "       [12.09904  ],\n",
       "       [11.815109 ],\n",
       "       [11.482114 ],\n",
       "       [11.739727 ],\n",
       "       [12.090999 ],\n",
       "       [12.211429 ],\n",
       "       [12.042303 ],\n",
       "       [11.69733  ],\n",
       "       [12.101362 ],\n",
       "       [12.177278 ],\n",
       "       [12.450082 ],\n",
       "       [12.423167 ],\n",
       "       [12.366893 ],\n",
       "       [11.567312 ],\n",
       "       [12.412052 ],\n",
       "       [12.116615 ],\n",
       "       [11.601441 ],\n",
       "       [12.23244  ],\n",
       "       [11.956692 ],\n",
       "       [11.937425 ],\n",
       "       [11.991768 ],\n",
       "       [12.036207 ],\n",
       "       [11.595721 ],\n",
       "       [12.48872  ],\n",
       "       [12.042465 ],\n",
       "       [11.737215 ],\n",
       "       [11.654763 ],\n",
       "       [11.850462 ],\n",
       "       [12.145019 ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 665us/step - loss: 0.0170 - mse: 0.0170\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy = model_2.evaluate(test_input_2,test_target_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8169910032683023\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(test_target_2,predictions_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python(tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
