{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Henry\\\\Desktop\\\\my Portfolio\\\\DEEPLEARNING_IOWA'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\henry\\anaconda3\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from keras) (1.19.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\henry\\anaconda3\\lib\\site-packages (from keras) (3.1.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from keras) (1.5.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\henry\\anaconda3\\lib\\site-packages (from keras) (5.3.1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import seed \n",
    "seed(1) \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "!pip install keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_8 = pd.read_csv('sensitivity_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>SalePrice_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.207142</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>1.050994</td>\n",
       "      <td>0.878668</td>\n",
       "      <td>0.575425</td>\n",
       "      <td>0.370333</td>\n",
       "      <td>-0.951226</td>\n",
       "      <td>0.311725</td>\n",
       "      <td>12.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.091886</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>0.156734</td>\n",
       "      <td>-0.429577</td>\n",
       "      <td>1.171992</td>\n",
       "      <td>-0.482512</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>0.311725</td>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotArea  OverallQual  YearBuilt  YearRemodAdd  BsmtFinSF1  GrLivArea  \\\n",
       "0 -0.207142     0.651479   1.050994      0.878668    0.575425   0.370333   \n",
       "1 -0.091886    -0.071836   0.156734     -0.429577    1.171992  -0.482512   \n",
       "\n",
       "   Fireplaces  GarageCars  SalePrice_log  \n",
       "0   -0.951226    0.311725      12.247694  \n",
       "1    0.600495    0.311725      12.109011  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity_8.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_4 = pd.read_csv('sensitivity_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>SalePrice_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.207142</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>1.050994</td>\n",
       "      <td>0.370333</td>\n",
       "      <td>12.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.091886</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>0.156734</td>\n",
       "      <td>-0.482512</td>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotArea  OverallQual  YearBuilt  GrLivArea  SalePrice_log\n",
       "0 -0.207142     0.651479   1.050994   0.370333      12.247694\n",
       "1 -0.091886    -0.071836   0.156734  -0.482512      12.109011"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity_4.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_4.columns = ['']*len(sensitivity_4.columns)\n",
    "sensitivity_4.index = ['']*len(sensitivity_4.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>-0.207142</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>1.050994</td>\n",
       "      <td>0.370333</td>\n",
       "      <td>12.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>-0.091886</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>0.156734</td>\n",
       "      <td>-0.482512</td>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   \n",
       " -0.207142  0.651479  1.050994  0.370333  12.247694\n",
       " -0.091886 -0.071836  0.156734 -0.482512  12.109011"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity_4.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_8.columns = ['']*len(sensitivity_8.columns)\n",
    "sensitivity_8.index = ['']*len(sensitivity_8.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>-0.207142</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>1.050994</td>\n",
       "      <td>0.878668</td>\n",
       "      <td>0.575425</td>\n",
       "      <td>0.370333</td>\n",
       "      <td>-0.951226</td>\n",
       "      <td>0.311725</td>\n",
       "      <td>12.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>-0.091886</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>0.156734</td>\n",
       "      <td>-0.429577</td>\n",
       "      <td>1.171992</td>\n",
       "      <td>-0.482512</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>0.311725</td>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        \\\n",
       " -0.207142  0.651479  1.050994  0.878668  0.575425  0.370333 -0.951226   \n",
       " -0.091886 -0.071836  0.156734 -0.429577  1.171992 -0.482512  0.600495   \n",
       "\n",
       "                       \n",
       "  0.311725  12.247694  \n",
       "  0.311725  12.109011  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity_8.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " train, validate, test = \\\n",
    "              np.split(sensitivity_8.sample(frac=1, random_state=42), \n",
    "                       [int(.6*len(sensitivity_8)), int(.8*len(sensitivity_8))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((876, 9), (292, 9), (292, 9))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input =train.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target= train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_input = validate.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_target= validate.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target= test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELING FOR 8 FEATURES\n",
    "# build the model using Keras approach\n",
    "input_size = 8   # number of features\n",
    "from sklearn.metrics import r2_score\n",
    "output_size = 1    \n",
    "hidden_layer_size =50  \n",
    "Early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "     tf.keras.layers.Dense(hidden_layer_size,activation = 'relu'),\n",
    "     tf.keras.layers.Dense(hidden_layer_size,activation = 'relu'),\n",
    "       tf.keras.layers.Dense(hidden_layer_size,activation = 'tanh'),\n",
    "     tf.keras.layers.Dense(hidden_layer_size,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(output_size,activation ='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss ='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 1s - loss: 139.7487 - mse: 139.7487 - val_loss: 129.8127 - val_mse: 129.8127\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 120.2148 - mse: 120.2148 - val_loss: 104.9515 - val_mse: 104.9515\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 88.8516 - mse: 88.8516 - val_loss: 64.9960 - val_mse: 64.9960\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 45.2609 - mse: 45.2609 - val_loss: 21.9263 - val_mse: 21.9263\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 10.4283 - mse: 10.4283 - val_loss: 2.1413 - val_mse: 2.1413\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 2.0254 - mse: 2.0254 - val_loss: 3.3238 - val_mse: 3.3238\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 3.0438 - mse: 3.0438 - val_loss: 1.9213 - val_mse: 1.9213\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 1.1431 - mse: 1.1431 - val_loss: 0.8247 - val_mse: 0.8247\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 0.8224 - mse: 0.8224 - val_loss: 0.9013 - val_mse: 0.9013\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 0.6948 - mse: 0.6948 - val_loss: 0.6231 - val_mse: 0.6231\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 0.5389 - mse: 0.5389 - val_loss: 0.5696 - val_mse: 0.5696\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 0.4777 - mse: 0.4777 - val_loss: 0.4835 - val_mse: 0.4835\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 0.4052 - mse: 0.4052 - val_loss: 0.4305 - val_mse: 0.4305\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 0.3590 - mse: 0.3590 - val_loss: 0.3820 - val_mse: 0.3820\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 0.3142 - mse: 0.3142 - val_loss: 0.3434 - val_mse: 0.3434\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 0.2840 - mse: 0.2840 - val_loss: 0.3099 - val_mse: 0.3099\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 0.2538 - mse: 0.2538 - val_loss: 0.2818 - val_mse: 0.2818\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 0.2303 - mse: 0.2303 - val_loss: 0.2564 - val_mse: 0.2564\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 0.2082 - mse: 0.2082 - val_loss: 0.2353 - val_mse: 0.2353\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 0.1905 - mse: 0.1905 - val_loss: 0.2164 - val_mse: 0.2164\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 0.1741 - mse: 0.1741 - val_loss: 0.2001 - val_mse: 0.2001\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 0.1602 - mse: 0.1602 - val_loss: 0.1856 - val_mse: 0.1856\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 0.1481 - mse: 0.1481 - val_loss: 0.1725 - val_mse: 0.1725\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 0.1367 - mse: 0.1367 - val_loss: 0.1611 - val_mse: 0.1611\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 0.1269 - mse: 0.1269 - val_loss: 0.1502 - val_mse: 0.1502\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 0.1176 - mse: 0.1176 - val_loss: 0.1399 - val_mse: 0.1399\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 0.1091 - mse: 0.1091 - val_loss: 0.1309 - val_mse: 0.1309\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 0.1014 - mse: 0.1014 - val_loss: 0.1231 - val_mse: 0.1231\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 0.0950 - mse: 0.0950 - val_loss: 0.1158 - val_mse: 0.1158\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 0.0890 - mse: 0.0890 - val_loss: 0.1091 - val_mse: 0.1091\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 0.0834 - mse: 0.0834 - val_loss: 0.1030 - val_mse: 0.1030\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 0.0784 - mse: 0.0784 - val_loss: 0.0972 - val_mse: 0.0972\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 0.0736 - mse: 0.0736 - val_loss: 0.0919 - val_mse: 0.0919\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 0.0691 - mse: 0.0691 - val_loss: 0.0869 - val_mse: 0.0869\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 0.0651 - mse: 0.0651 - val_loss: 0.0822 - val_mse: 0.0822\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 0.0620 - mse: 0.0620 - val_loss: 0.0778 - val_mse: 0.0778\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 0.0582 - mse: 0.0582 - val_loss: 0.0736 - val_mse: 0.0736\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0698 - val_mse: 0.0698\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0662 - val_mse: 0.0662\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0628 - val_mse: 0.0628\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 0.0439 - mse: 0.0439 - val_loss: 0.0569 - val_mse: 0.0569\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 0.0419 - mse: 0.0419 - val_loss: 0.0543 - val_mse: 0.0543\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0521 - val_mse: 0.0521\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0497 - val_mse: 0.0497\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0481 - val_mse: 0.0481\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0459 - val_mse: 0.0459\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0428 - val_mse: 0.0428\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0413 - val_mse: 0.0413\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0401 - val_mse: 0.0401\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0369 - val_mse: 0.0369\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 65/100\n",
      "9/9 - 0s - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 67/100\n",
      "9/9 - 0s - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 68/100\n",
      "9/9 - 0s - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 69/100\n",
      "9/9 - 0s - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 70/100\n",
      "9/9 - 0s - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 71/100\n",
      "9/9 - 0s - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 72/100\n",
      "9/9 - 0s - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 73/100\n",
      "9/9 - 0s - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 74/100\n",
      "9/9 - 0s - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 75/100\n",
      "9/9 - 0s - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 76/100\n",
      "9/9 - 0s - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 77/100\n",
      "9/9 - 0s - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 78/100\n",
      "9/9 - 0s - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 79/100\n",
      "9/9 - 0s - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 80/100\n",
      "9/9 - 0s - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 81/100\n",
      "9/9 - 0s - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 82/100\n",
      "9/9 - 0s - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 83/100\n",
      "9/9 - 0s - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 84/100\n",
      "9/9 - 0s - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 85/100\n",
      "9/9 - 0s - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 86/100\n",
      "9/9 - 0s - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 87/100\n",
      "9/9 - 0s - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 88/100\n",
      "9/9 - 0s - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 89/100\n",
      "9/9 - 0s - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 90/100\n",
      "9/9 - 0s - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 91/100\n",
      "9/9 - 0s - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 92/100\n",
      "9/9 - 0s - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 93/100\n",
      "9/9 - 0s - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0207 - val_mse: 0.0207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "9/9 - 0s - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 95/100\n",
      "9/9 - 0s - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 96/100\n",
      "9/9 - 0s - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 97/100\n",
      "9/9 - 0s - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0211 - val_mse: 0.0211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19e3a50a220>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "max_epochs= 100\n",
    "model.fit(train_input,train_target,batch_size=batch_size ,epochs=max_epochs,callbacks=[Early_stopping],validation_data=(validation_input ,validation_target),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.901176 ],\n",
       "       [11.806044 ],\n",
       "       [12.068634 ],\n",
       "       [12.045199 ],\n",
       "       [11.980535 ],\n",
       "       [12.087177 ],\n",
       "       [12.482881 ],\n",
       "       [12.277623 ],\n",
       "       [11.660876 ],\n",
       "       [11.672033 ],\n",
       "       [11.749396 ],\n",
       "       [11.695261 ],\n",
       "       [12.241548 ],\n",
       "       [12.060266 ],\n",
       "       [12.019826 ],\n",
       "       [11.653686 ],\n",
       "       [11.714055 ],\n",
       "       [11.917298 ],\n",
       "       [12.139851 ],\n",
       "       [11.8932085],\n",
       "       [12.044255 ],\n",
       "       [11.937841 ],\n",
       "       [12.3195305],\n",
       "       [11.647473 ],\n",
       "       [12.280269 ],\n",
       "       [12.265503 ],\n",
       "       [12.164261 ],\n",
       "       [12.009535 ],\n",
       "       [11.869885 ],\n",
       "       [11.884629 ],\n",
       "       [11.727906 ],\n",
       "       [11.656918 ],\n",
       "       [12.3682785],\n",
       "       [12.492309 ],\n",
       "       [11.93394  ],\n",
       "       [12.156445 ],\n",
       "       [12.329614 ],\n",
       "       [11.756604 ],\n",
       "       [11.654625 ],\n",
       "       [12.017724 ],\n",
       "       [12.153087 ],\n",
       "       [11.759024 ],\n",
       "       [11.553984 ],\n",
       "       [11.635996 ],\n",
       "       [12.462601 ],\n",
       "       [12.448453 ],\n",
       "       [12.488199 ],\n",
       "       [11.708246 ],\n",
       "       [11.658964 ],\n",
       "       [12.317065 ],\n",
       "       [11.621855 ],\n",
       "       [12.004269 ],\n",
       "       [11.74623  ],\n",
       "       [11.78094  ],\n",
       "       [12.222019 ],\n",
       "       [12.088501 ],\n",
       "       [11.554246 ],\n",
       "       [11.6108   ],\n",
       "       [11.713177 ],\n",
       "       [12.041252 ],\n",
       "       [11.817528 ],\n",
       "       [12.035627 ],\n",
       "       [11.804201 ],\n",
       "       [12.436634 ],\n",
       "       [11.720845 ],\n",
       "       [11.805504 ],\n",
       "       [12.0012   ],\n",
       "       [12.4012575],\n",
       "       [11.766492 ],\n",
       "       [12.334482 ],\n",
       "       [11.810854 ],\n",
       "       [12.417437 ],\n",
       "       [12.135609 ],\n",
       "       [11.548214 ],\n",
       "       [11.888471 ],\n",
       "       [11.674213 ],\n",
       "       [11.662145 ],\n",
       "       [11.776261 ],\n",
       "       [11.633204 ],\n",
       "       [11.8055   ],\n",
       "       [11.878363 ],\n",
       "       [12.070222 ],\n",
       "       [11.937866 ],\n",
       "       [12.3836565],\n",
       "       [12.425042 ],\n",
       "       [12.206987 ],\n",
       "       [12.051246 ],\n",
       "       [12.518492 ],\n",
       "       [12.392184 ],\n",
       "       [11.688188 ],\n",
       "       [12.293338 ],\n",
       "       [12.429014 ],\n",
       "       [12.211411 ],\n",
       "       [12.255782 ],\n",
       "       [11.724602 ],\n",
       "       [12.111904 ],\n",
       "       [11.730267 ],\n",
       "       [11.815949 ],\n",
       "       [11.82256  ],\n",
       "       [12.457292 ],\n",
       "       [12.430652 ],\n",
       "       [11.816012 ],\n",
       "       [12.379819 ],\n",
       "       [12.38183  ],\n",
       "       [11.900603 ],\n",
       "       [12.022399 ],\n",
       "       [12.395798 ],\n",
       "       [12.031451 ],\n",
       "       [12.485951 ],\n",
       "       [11.764257 ],\n",
       "       [11.962427 ],\n",
       "       [11.691402 ],\n",
       "       [11.821242 ],\n",
       "       [12.431877 ],\n",
       "       [11.636317 ],\n",
       "       [11.744839 ],\n",
       "       [12.470041 ],\n",
       "       [11.838981 ],\n",
       "       [12.160857 ],\n",
       "       [11.559167 ],\n",
       "       [11.805968 ],\n",
       "       [12.4351425],\n",
       "       [12.028302 ],\n",
       "       [11.654361 ],\n",
       "       [11.915076 ],\n",
       "       [11.762995 ],\n",
       "       [11.976184 ],\n",
       "       [12.153775 ],\n",
       "       [12.023729 ],\n",
       "       [12.251438 ],\n",
       "       [12.1665   ],\n",
       "       [12.326461 ],\n",
       "       [11.900887 ],\n",
       "       [11.744203 ],\n",
       "       [11.937266 ],\n",
       "       [11.741646 ],\n",
       "       [11.690516 ],\n",
       "       [11.937531 ],\n",
       "       [12.468457 ],\n",
       "       [11.908106 ],\n",
       "       [11.7416725],\n",
       "       [12.4685955],\n",
       "       [12.048852 ],\n",
       "       [12.48587  ],\n",
       "       [11.626562 ],\n",
       "       [12.369401 ],\n",
       "       [12.015098 ],\n",
       "       [11.78228  ],\n",
       "       [11.955242 ],\n",
       "       [12.013915 ],\n",
       "       [11.875143 ],\n",
       "       [11.964966 ],\n",
       "       [12.025071 ],\n",
       "       [11.78446  ],\n",
       "       [11.898574 ],\n",
       "       [11.707078 ],\n",
       "       [11.861091 ],\n",
       "       [11.647978 ],\n",
       "       [12.321768 ],\n",
       "       [11.649888 ],\n",
       "       [11.920851 ],\n",
       "       [12.184224 ],\n",
       "       [12.1521   ],\n",
       "       [12.17377  ],\n",
       "       [11.743465 ],\n",
       "       [12.418762 ],\n",
       "       [12.488424 ],\n",
       "       [11.71778  ],\n",
       "       [11.736915 ],\n",
       "       [12.475125 ],\n",
       "       [11.609872 ],\n",
       "       [11.712335 ],\n",
       "       [11.817287 ],\n",
       "       [11.802131 ],\n",
       "       [11.756012 ],\n",
       "       [12.193854 ],\n",
       "       [12.417909 ],\n",
       "       [12.025924 ],\n",
       "       [11.836441 ],\n",
       "       [11.814238 ],\n",
       "       [12.107619 ],\n",
       "       [11.885579 ],\n",
       "       [12.253127 ],\n",
       "       [11.739269 ],\n",
       "       [12.45943  ],\n",
       "       [11.660655 ],\n",
       "       [11.651529 ],\n",
       "       [12.307304 ],\n",
       "       [11.964777 ],\n",
       "       [11.754131 ],\n",
       "       [11.680991 ],\n",
       "       [11.872985 ],\n",
       "       [12.03305  ],\n",
       "       [11.609795 ],\n",
       "       [12.29897  ],\n",
       "       [11.833806 ],\n",
       "       [12.393874 ],\n",
       "       [11.783468 ],\n",
       "       [12.103283 ],\n",
       "       [12.136236 ],\n",
       "       [11.723171 ],\n",
       "       [12.500246 ],\n",
       "       [12.226126 ],\n",
       "       [11.970397 ],\n",
       "       [11.664231 ],\n",
       "       [11.9615555],\n",
       "       [12.243563 ],\n",
       "       [11.697729 ],\n",
       "       [11.974885 ],\n",
       "       [12.296573 ],\n",
       "       [11.871716 ],\n",
       "       [12.133717 ],\n",
       "       [12.280624 ],\n",
       "       [12.107524 ],\n",
       "       [11.814692 ],\n",
       "       [11.646449 ],\n",
       "       [12.0460825],\n",
       "       [12.490951 ],\n",
       "       [11.666688 ],\n",
       "       [12.082145 ],\n",
       "       [12.435353 ],\n",
       "       [11.934774 ],\n",
       "       [11.773399 ],\n",
       "       [12.145314 ],\n",
       "       [11.709218 ],\n",
       "       [11.719129 ],\n",
       "       [11.859321 ],\n",
       "       [12.387911 ],\n",
       "       [12.058631 ],\n",
       "       [11.857009 ],\n",
       "       [11.926475 ],\n",
       "       [12.272667 ],\n",
       "       [11.776608 ],\n",
       "       [11.994796 ],\n",
       "       [11.973836 ],\n",
       "       [12.456607 ],\n",
       "       [12.427613 ],\n",
       "       [12.1822405],\n",
       "       [11.676306 ],\n",
       "       [12.225117 ],\n",
       "       [12.196819 ],\n",
       "       [12.479598 ],\n",
       "       [11.785381 ],\n",
       "       [12.009329 ],\n",
       "       [11.876763 ],\n",
       "       [11.771119 ],\n",
       "       [12.4469   ],\n",
       "       [11.70295  ],\n",
       "       [12.388672 ],\n",
       "       [12.01373  ],\n",
       "       [12.493343 ],\n",
       "       [11.635988 ],\n",
       "       [11.979363 ],\n",
       "       [12.178726 ],\n",
       "       [11.73634  ],\n",
       "       [12.33394  ],\n",
       "       [12.094149 ],\n",
       "       [12.049233 ],\n",
       "       [11.955569 ],\n",
       "       [12.131483 ],\n",
       "       [12.3470745],\n",
       "       [11.763662 ],\n",
       "       [11.896867 ],\n",
       "       [12.064243 ],\n",
       "       [11.732753 ],\n",
       "       [11.527221 ],\n",
       "       [11.696909 ],\n",
       "       [12.191697 ],\n",
       "       [12.100962 ],\n",
       "       [11.992947 ],\n",
       "       [11.651417 ],\n",
       "       [12.062606 ],\n",
       "       [12.144938 ],\n",
       "       [12.464127 ],\n",
       "       [12.363521 ],\n",
       "       [12.445856 ],\n",
       "       [11.597788 ],\n",
       "       [12.39927  ],\n",
       "       [12.033625 ],\n",
       "       [11.648727 ],\n",
       "       [12.024632 ],\n",
       "       [11.995135 ],\n",
       "       [11.773184 ],\n",
       "       [12.001275 ],\n",
       "       [12.090231 ],\n",
       "       [11.613559 ],\n",
       "       [12.476056 ],\n",
       "       [11.979271 ],\n",
       "       [11.891553 ],\n",
       "       [11.67662  ],\n",
       "       [11.877119 ],\n",
       "       [12.1056185]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 554us/step - loss: 0.0177 - mse: 0.0177\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy = model.evaluate(test_input,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8095026455802128\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(test_target,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case for sensitivity_4 \n",
    "train, validate, test = \\\n",
    "              np.split(sensitivity_4.sample(frac=1, random_state=42), \n",
    "                       [int(.6*len(sensitivity_4)), int(.8*len(sensitivity_4))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((876, 5), (292, 5), (292, 5))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_2 =train.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_2= train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_input_2 =validate.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_target_2= validate.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_2 =test.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target_2= test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4   # number of features\n",
    "\n",
    "output_size = 1    \n",
    "hidden_layer_size =100  \n",
    "Early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "     tf.keras.layers.Dense(hidden_layer_size,activation = 'relu'),\n",
    "     tf.keras.layers.Dense(hidden_layer_size,activation = 'relu'),\n",
    "       tf.keras.layers.Dense(hidden_layer_size,activation = 'tanh'),\n",
    "     tf.keras.layers.Dense(hidden_layer_size,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(output_size,activation ='linear')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer='adam',loss ='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 0s - loss: 127.4771 - mse: 127.4771 - val_loss: 100.5066 - val_mse: 100.5066\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 73.8070 - mse: 73.8070 - val_loss: 31.1782 - val_mse: 31.1782\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 16.6402 - mse: 16.6402 - val_loss: 19.8589 - val_mse: 19.8589\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 13.6410 - mse: 13.6410 - val_loss: 7.3947 - val_mse: 7.3947\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 6.4235 - mse: 6.4235 - val_loss: 7.0106 - val_mse: 7.0106\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 5.1371 - mse: 5.1371 - val_loss: 4.4494 - val_mse: 4.4494\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 3.6395 - mse: 3.6395 - val_loss: 3.6030 - val_mse: 3.6030\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 2.6802 - mse: 2.6802 - val_loss: 2.6470 - val_mse: 2.6470\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 2.0427 - mse: 2.0427 - val_loss: 1.9386 - val_mse: 1.9386\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 1.4766 - mse: 1.4766 - val_loss: 1.3935 - val_mse: 1.3935\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 1.0751 - mse: 1.0751 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 0.7637 - mse: 0.7637 - val_loss: 0.7079 - val_mse: 0.7079\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 0.5522 - mse: 0.5522 - val_loss: 0.5057 - val_mse: 0.5057\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 0.3986 - mse: 0.3986 - val_loss: 0.3668 - val_mse: 0.3668\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 0.2961 - mse: 0.2961 - val_loss: 0.2721 - val_mse: 0.2721\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 0.2229 - mse: 0.2229 - val_loss: 0.2072 - val_mse: 0.2072\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 0.1739 - mse: 0.1739 - val_loss: 0.1623 - val_mse: 0.1623\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 0.1389 - mse: 0.1389 - val_loss: 0.1313 - val_mse: 0.1313\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 0.1145 - mse: 0.1145 - val_loss: 0.1092 - val_mse: 0.1092\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 0.0970 - mse: 0.0970 - val_loss: 0.0934 - val_mse: 0.0934\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 0.0841 - mse: 0.0841 - val_loss: 0.0817 - val_mse: 0.0817\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 0.0744 - mse: 0.0744 - val_loss: 0.0728 - val_mse: 0.0728\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 0.0669 - mse: 0.0669 - val_loss: 0.0658 - val_mse: 0.0658\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 0.0609 - mse: 0.0609 - val_loss: 0.0602 - val_mse: 0.0602\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0555 - val_mse: 0.0555\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0516 - val_mse: 0.0516\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0483 - val_mse: 0.0483\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0454 - val_mse: 0.0454\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0428 - val_mse: 0.0428\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 0.0406 - mse: 0.0406 - val_loss: 0.0406 - val_mse: 0.0406\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0369 - val_mse: 0.0369\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0313 - val_mse: 0.0313\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0200 - val_mse: 0.0200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19e42f14a30>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "max_epochs= 100\n",
    "model_2.fit(train_input_2,train_target_2,shuffle=False,batch_size=batch_size ,epochs=max_epochs,callbacks=[Early_stopping],validation_data=(validate_input_2 ,validate_target_2),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_1 = model_2.predict(test_input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.847903 ],\n",
       "       [12.1174   ],\n",
       "       [11.950408 ],\n",
       "       [12.086862 ],\n",
       "       [12.034939 ],\n",
       "       [12.026076 ],\n",
       "       [12.461662 ],\n",
       "       [12.281774 ],\n",
       "       [11.654733 ],\n",
       "       [11.797441 ],\n",
       "       [11.665277 ],\n",
       "       [11.672776 ],\n",
       "       [12.180331 ],\n",
       "       [12.107657 ],\n",
       "       [11.776538 ],\n",
       "       [11.725488 ],\n",
       "       [11.697496 ],\n",
       "       [12.062096 ],\n",
       "       [12.131373 ],\n",
       "       [11.908531 ],\n",
       "       [11.989114 ],\n",
       "       [11.926061 ],\n",
       "       [12.2174635],\n",
       "       [11.7355795],\n",
       "       [12.352445 ],\n",
       "       [12.213433 ],\n",
       "       [12.033722 ],\n",
       "       [12.16685  ],\n",
       "       [11.912813 ],\n",
       "       [11.826657 ],\n",
       "       [11.529823 ],\n",
       "       [11.597982 ],\n",
       "       [12.344158 ],\n",
       "       [12.448113 ],\n",
       "       [11.97248  ],\n",
       "       [12.202413 ],\n",
       "       [12.33333  ],\n",
       "       [11.740758 ],\n",
       "       [11.686199 ],\n",
       "       [12.0457945],\n",
       "       [12.122468 ],\n",
       "       [11.688776 ],\n",
       "       [11.430102 ],\n",
       "       [11.726128 ],\n",
       "       [12.374898 ],\n",
       "       [12.410231 ],\n",
       "       [12.449384 ],\n",
       "       [11.649987 ],\n",
       "       [11.688468 ],\n",
       "       [12.2338295],\n",
       "       [11.625117 ],\n",
       "       [11.990675 ],\n",
       "       [11.900179 ],\n",
       "       [11.773345 ],\n",
       "       [12.152751 ],\n",
       "       [12.12684  ],\n",
       "       [11.76529  ],\n",
       "       [11.55448  ],\n",
       "       [11.773046 ],\n",
       "       [11.849372 ],\n",
       "       [11.855592 ],\n",
       "       [12.001842 ],\n",
       "       [11.871161 ],\n",
       "       [12.390496 ],\n",
       "       [11.806455 ],\n",
       "       [11.771485 ],\n",
       "       [11.922483 ],\n",
       "       [12.358466 ],\n",
       "       [11.913663 ],\n",
       "       [12.330386 ],\n",
       "       [11.822282 ],\n",
       "       [12.407617 ],\n",
       "       [11.7864485],\n",
       "       [11.505397 ],\n",
       "       [11.824951 ],\n",
       "       [11.582369 ],\n",
       "       [11.620404 ],\n",
       "       [11.87173  ],\n",
       "       [11.4904995],\n",
       "       [11.87585  ],\n",
       "       [11.980845 ],\n",
       "       [12.085933 ],\n",
       "       [12.19555  ],\n",
       "       [12.312879 ],\n",
       "       [12.303605 ],\n",
       "       [12.164123 ],\n",
       "       [12.095727 ],\n",
       "       [12.427618 ],\n",
       "       [12.299553 ],\n",
       "       [11.7226515],\n",
       "       [12.294548 ],\n",
       "       [12.377528 ],\n",
       "       [12.172307 ],\n",
       "       [12.354587 ],\n",
       "       [11.855968 ],\n",
       "       [12.1506815],\n",
       "       [11.747521 ],\n",
       "       [11.627498 ],\n",
       "       [11.832128 ],\n",
       "       [12.322258 ],\n",
       "       [12.354104 ],\n",
       "       [11.672118 ],\n",
       "       [12.149253 ],\n",
       "       [12.274306 ],\n",
       "       [12.016515 ],\n",
       "       [12.004243 ],\n",
       "       [12.285657 ],\n",
       "       [11.797692 ],\n",
       "       [12.3618145],\n",
       "       [11.71145  ],\n",
       "       [11.819332 ],\n",
       "       [11.71629  ],\n",
       "       [11.980674 ],\n",
       "       [12.457459 ],\n",
       "       [11.762751 ],\n",
       "       [11.856149 ],\n",
       "       [12.486672 ],\n",
       "       [11.727839 ],\n",
       "       [12.176221 ],\n",
       "       [11.529714 ],\n",
       "       [11.757056 ],\n",
       "       [12.391822 ],\n",
       "       [11.999581 ],\n",
       "       [11.702559 ],\n",
       "       [11.776322 ],\n",
       "       [11.84888  ],\n",
       "       [11.79188  ],\n",
       "       [12.0276165],\n",
       "       [11.906297 ],\n",
       "       [12.283312 ],\n",
       "       [12.174719 ],\n",
       "       [12.326346 ],\n",
       "       [11.726448 ],\n",
       "       [11.885851 ],\n",
       "       [11.855466 ],\n",
       "       [11.8323965],\n",
       "       [11.719505 ],\n",
       "       [11.850974 ],\n",
       "       [12.401975 ],\n",
       "       [11.931874 ],\n",
       "       [11.641421 ],\n",
       "       [12.385223 ],\n",
       "       [12.031183 ],\n",
       "       [12.499318 ],\n",
       "       [11.714321 ],\n",
       "       [12.205755 ],\n",
       "       [11.846751 ],\n",
       "       [11.716248 ],\n",
       "       [12.002168 ],\n",
       "       [11.766433 ],\n",
       "       [12.014163 ],\n",
       "       [11.957273 ],\n",
       "       [12.104953 ],\n",
       "       [11.743602 ],\n",
       "       [11.857879 ],\n",
       "       [11.739115 ],\n",
       "       [11.9791355],\n",
       "       [11.694676 ],\n",
       "       [12.254341 ],\n",
       "       [11.686799 ],\n",
       "       [11.980166 ],\n",
       "       [12.108255 ],\n",
       "       [12.007812 ],\n",
       "       [12.256425 ],\n",
       "       [11.779532 ],\n",
       "       [12.394677 ],\n",
       "       [12.423351 ],\n",
       "       [11.677459 ],\n",
       "       [11.635033 ],\n",
       "       [12.421683 ],\n",
       "       [11.588985 ],\n",
       "       [11.739792 ],\n",
       "       [11.950751 ],\n",
       "       [11.786704 ],\n",
       "       [11.757077 ],\n",
       "       [12.102658 ],\n",
       "       [12.381434 ],\n",
       "       [11.88976  ],\n",
       "       [11.762242 ],\n",
       "       [11.972902 ],\n",
       "       [12.163556 ],\n",
       "       [11.741246 ],\n",
       "       [12.202993 ],\n",
       "       [11.822803 ],\n",
       "       [12.443922 ],\n",
       "       [11.73363  ],\n",
       "       [11.690885 ],\n",
       "       [12.262707 ],\n",
       "       [11.716043 ],\n",
       "       [11.720958 ],\n",
       "       [11.6909485],\n",
       "       [11.877524 ],\n",
       "       [12.11296  ],\n",
       "       [11.511282 ],\n",
       "       [12.326366 ],\n",
       "       [11.848309 ],\n",
       "       [12.3698635],\n",
       "       [11.801366 ],\n",
       "       [12.1648245],\n",
       "       [12.178998 ],\n",
       "       [11.728049 ],\n",
       "       [12.436343 ],\n",
       "       [12.142037 ],\n",
       "       [11.8992815],\n",
       "       [11.796846 ],\n",
       "       [11.800307 ],\n",
       "       [12.169544 ],\n",
       "       [11.754209 ],\n",
       "       [11.874743 ],\n",
       "       [12.202567 ],\n",
       "       [11.989965 ],\n",
       "       [12.048705 ],\n",
       "       [12.225213 ],\n",
       "       [12.248729 ],\n",
       "       [11.840305 ],\n",
       "       [11.633682 ],\n",
       "       [11.806602 ],\n",
       "       [12.466981 ],\n",
       "       [11.555785 ],\n",
       "       [12.114841 ],\n",
       "       [12.4273405],\n",
       "       [11.738983 ],\n",
       "       [11.775504 ],\n",
       "       [12.066603 ],\n",
       "       [11.717623 ],\n",
       "       [11.794601 ],\n",
       "       [12.148763 ],\n",
       "       [12.318133 ],\n",
       "       [11.941194 ],\n",
       "       [11.986423 ],\n",
       "       [11.861352 ],\n",
       "       [12.151098 ],\n",
       "       [11.77367  ],\n",
       "       [12.07718  ],\n",
       "       [12.144871 ],\n",
       "       [12.373741 ],\n",
       "       [12.359572 ],\n",
       "       [12.259336 ],\n",
       "       [11.613299 ],\n",
       "       [12.204685 ],\n",
       "       [12.130108 ],\n",
       "       [12.409136 ],\n",
       "       [11.833389 ],\n",
       "       [11.922483 ],\n",
       "       [11.991769 ],\n",
       "       [11.898578 ],\n",
       "       [12.450575 ],\n",
       "       [11.690436 ],\n",
       "       [12.286641 ],\n",
       "       [11.993056 ],\n",
       "       [12.496596 ],\n",
       "       [11.749237 ],\n",
       "       [11.858448 ],\n",
       "       [12.283865 ],\n",
       "       [11.725087 ],\n",
       "       [12.243056 ],\n",
       "       [12.022829 ],\n",
       "       [12.063087 ],\n",
       "       [11.892115 ],\n",
       "       [12.141772 ],\n",
       "       [12.266902 ],\n",
       "       [11.899579 ],\n",
       "       [11.920313 ],\n",
       "       [12.135659 ],\n",
       "       [11.892121 ],\n",
       "       [11.518233 ],\n",
       "       [11.725396 ],\n",
       "       [11.947501 ],\n",
       "       [12.186148 ],\n",
       "       [12.025632 ],\n",
       "       [11.700755 ],\n",
       "       [12.083365 ],\n",
       "       [12.216217 ],\n",
       "       [12.428681 ],\n",
       "       [12.377881 ],\n",
       "       [12.3749275],\n",
       "       [11.541846 ],\n",
       "       [12.382334 ],\n",
       "       [12.099242 ],\n",
       "       [11.639791 ],\n",
       "       [12.022168 ],\n",
       "       [11.975592 ],\n",
       "       [11.974155 ],\n",
       "       [12.0154705],\n",
       "       [12.028997 ],\n",
       "       [11.586349 ],\n",
       "       [12.426415 ],\n",
       "       [12.05189  ],\n",
       "       [11.756464 ],\n",
       "       [11.679489 ],\n",
       "       [11.855248 ],\n",
       "       [12.121057 ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 554us/step - loss: 0.0204 - mse: 0.0204\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy = model_2.evaluate(test_input_2,test_target_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7807557987222327\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(test_target_2,predictions_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python(tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
